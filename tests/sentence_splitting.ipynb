{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b589de72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from alive_progress import alive_bar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52f4456a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_text(dataframe, parsed_docs_folder):\n",
    "    fr_texts = []\n",
    "    en_texts = []\n",
    "\n",
    "    with alive_bar(len(dataframe), force_tty=True) as bar:\n",
    "        for _, row in dataframe.iterrows():\n",
    "            bar()\n",
    "\n",
    "            filename_fr = row['filename_fr']\n",
    "            filename_en = row['filename_en']\n",
    "\n",
    "            def get_json_path(pdf_filename):\n",
    "                if pdf_filename.endswith(\".pdf\"):\n",
    "                    json_filename = pdf_filename + \".json\"\n",
    "                    for root, _, files in os.walk(parsed_docs_folder):\n",
    "                        if json_filename in files:\n",
    "                            return os.path.join(root, json_filename)\n",
    "                return None\n",
    "\n",
    "            def load_raw_text(json_path):\n",
    "                if json_path and os.path.exists(json_path):\n",
    "                    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "                        data = json.load(f)\n",
    "                        return data.get('text', '')\n",
    "                return ''\n",
    "\n",
    "            fr_link = get_json_path(filename_fr)\n",
    "            fr_text = load_raw_text(fr_link)\n",
    "\n",
    "            if filename_fr == filename_en:\n",
    "                en_text = fr_text\n",
    "            else:\n",
    "                en_link = get_json_path(filename_en)\n",
    "                en_text = load_raw_text(en_link)\n",
    "\n",
    "            fr_texts.append(fr_text)\n",
    "            en_texts.append(en_text)\n",
    "\n",
    "    dataframe['fr_text'] = fr_texts\n",
    "    dataframe['en_text'] = en_texts\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "filename = \"../../Data/fr_eng_correlation_data.csv\"\n",
    "docs_folder = \"../../Data/ParsedPublications\"\n",
    "testing_pickle = \"testing_df.pickle\"\n",
    "\n",
    "if os.path.exists(testing_pickle):\n",
    "    df = pd.read_pickle(testing_pickle)\n",
    "else:\n",
    "    df = pd.read_csv(filename)\n",
    "    df = add_text(df, docs_folder)\n",
    "    df.to_pickle(testing_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "85e36044",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUOTE_END_PATTERN = re.compile(r'[.!?][\"\\'\"»\"\\']+\\s')\n",
    "\n",
    "KNOWN_ABBREVS = {\n",
    "    'dr', 'mr', 'mrs', 'ms', 'prof', 'sr', 'jr', 'rev', 'hon', 'gov', 'gen', 'col', 'lt', 'sgt',\n",
    "    'mme', 'mlle', 'me', 'pr', 'mgr',\n",
    "    'st', 'ste', 'mt', 'ft', 'ave', 'blvd', 'rd', 'apt',\n",
    "    'inc', 'ltd', 'corp', 'co', 'bros', 'assn', 'dept',\n",
    "    'vs', 'etc', 'al', 'eg', 'ie', 'viz', 'approx', 'ca', 'cf',\n",
    "    'jan', 'feb', 'mar', 'apr', 'jun', 'jul', 'aug', 'sep', 'sept', 'oct', 'nov', 'dec',\n",
    "    'janv', 'fevr', 'avr', 'juil',\n",
    "    'no', 'nos', 'vol', 'vols', 'ed', 'eds', 'ch', 'sec', 'fig', 'figs',\n",
    "    'pp', 'pg', 'pgs',\n",
    "    'op', 'cit', 'loc', 'ibid', 'et', 'seq',\n",
    "    'misc', 'govt', 'natl', 'intl',\n",
    "}\n",
    "\n",
    "\n",
    "def is_likely_abbreviation(word):\n",
    "    w = word.lower().rstrip('.')\n",
    "    if len(w) <= 1:\n",
    "        return False\n",
    "    if w in KNOWN_ABBREVS:\n",
    "        return True\n",
    "    if len(w) <= 4 and w.isupper():\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def scan_for_patterns(dataframe, fr_col='fr_text', en_col='en_text'):\n",
    "    en_abbrevs = Counter()\n",
    "    fr_abbrevs = Counter()\n",
    "    \n",
    "    pattern = re.compile(r'\\b([A-Za-zÀ-ÿ]{2,5})\\.\\s+([A-ZÀ-Ÿ])')\n",
    "    \n",
    "    for idx, row in dataframe.iterrows():\n",
    "        if pd.notna(row.get(en_col)):\n",
    "            text = str(row[en_col])\n",
    "            for m in pattern.finditer(text):\n",
    "                word = m.group(1).lower()\n",
    "                if is_likely_abbreviation(word):\n",
    "                    en_abbrevs[word] += 1\n",
    "        \n",
    "        if pd.notna(row.get(fr_col)):\n",
    "            text = str(row[fr_col])\n",
    "            for m in pattern.finditer(text):\n",
    "                word = m.group(1).lower()\n",
    "                if is_likely_abbreviation(word):\n",
    "                    fr_abbrevs[word] += 1\n",
    "    \n",
    "    return {\n",
    "        'en_abbrevs': en_abbrevs,\n",
    "        'fr_abbrevs': fr_abbrevs,\n",
    "    }\n",
    "\n",
    "\n",
    "def print_scan_results(results, min_count=2):\n",
    "    print(\"=\" * 60)\n",
    "    print(\"PATTERN SCAN RESULTS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(\"\\nEnglish abbreviations:\")\n",
    "    for abbrev, count in results['en_abbrevs'].most_common(30):\n",
    "        if count >= min_count:\n",
    "            print(f\"  {abbrev:10} : {count}\")\n",
    "    \n",
    "    print(\"\\nFrench abbreviations:\")\n",
    "    for abbrev, count in results['fr_abbrevs'].most_common(30):\n",
    "        if count >= min_count:\n",
    "            print(f\"  {abbrev:10} : {count}\")\n",
    "    \n",
    "    print(f\"\\nQuote-ending sentences: EN={results['quote_endings']['en']}, FR={results['quote_endings']['fr']}\")\n",
    "\n",
    "\n",
    "def get_exemption_list(results, min_count=1):\n",
    "    combined = results['en_abbrevs'] + results['fr_abbrevs']\n",
    "    return [abbrev for abbrev, count in combined.most_common() if count >= min_count]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47234f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# may as well include all of them\n",
    "results = scan_for_patterns(df)\n",
    "len(get_exemption_list(results, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2d8101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['al', 'apr', 'assn', 'aug', 'ave', 'avr', 'blvd', 'bros', 'ca', 'cf', 'ch', 'cit', 'co', 'col', 'corp', 'dec', 'dept', 'dr', 'ed', 'eds', 'eg', 'et', 'etc', 'feb', 'fig', 'figs', 'ft', 'gen', 'gov', 'govt', 'hon', 'ibid', 'ie', 'inc', 'intl', 'jan', 'janv', 'jr', 'juil', 'jul', 'jun', 'loc', 'lt', 'ltd', 'mar', 'me', 'mgr', 'misc', 'mlle', 'mme', 'mr', 'mrs', 'ms', 'mt', 'natl', 'no', 'nos', 'nov', 'oct', 'op', 'pg', 'pgs', 'pp', 'pr', 'prof', 'rd', 'rev', 'sec', 'sep', 'sept', 'seq', 'sr', 'st', 'ste', 'viz', 'vol', 'vols', 'vs']\n"
     ]
    }
   ],
   "source": [
    "# final list of exemptions\n",
    "print(sorted(get_exemption_list(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ba3751",
   "metadata": {},
   "outputs": [],
   "source": [
    "_EXEMPTIONS = {\n",
    "    'al', 'apr', 'assn', 'aug', 'ave', 'avr', 'blvd', 'bros', 'ca', 'cf', 'ch', 'cit', 'co', 'col', 'corp', 'dec', \n",
    "    'dept', 'dr', 'ed', 'eds', 'eg', 'et', 'etc', 'feb', 'fig', 'figs', 'ft', 'gen', 'gov', 'govt', 'hon', 'ibid', \n",
    "    'ie', 'inc', 'intl', 'jan', 'janv', 'jr', 'juil', 'jul', 'jun', 'loc', 'lt', 'ltd', 'mar', 'me', 'mgr', 'misc', \n",
    "    'mlle', 'mme', 'mr', 'mrs', 'ms', 'mt', 'natl', 'no', 'nos', 'nov', 'oct', 'op', 'pg', 'pgs', 'pp', 'pr', \n",
    "    'prof', 'rd', 'rev', 'sec', 'sep', 'sept', 'seq', 'sr', 'st', 'ste', 'viz', 'vol', 'vols', 'vs'\n",
    "}\n",
    "_EXEMPT_PATTERN = re.compile(\n",
    "    r'\\b(' + '|'.join(re.escape(e) for e in sorted(_EXEMPTIONS, key=len, reverse=True)) + r')\\.\\s',\n",
    "    re.IGNORECASE\n",
    ")\n",
    "_SPLIT_PATTERN = re.compile(r'([.?!][\"\\'\\u00BB\\u201D\\u2019]*)\\s+')\n",
    "\n",
    "def split_text(text):\n",
    "    protected = _EXEMPT_PATTERN.sub(lambda m: m.group().replace('.', '\\x00'), text)\n",
    "    parts = _SPLIT_PATTERN.split(protected)\n",
    "    sentences = []\n",
    "    for i in range(0, len(parts) - 1, 2):\n",
    "        sentences.append((parts[i] + parts[i + 1]).replace('\\x00', '.').strip())\n",
    "    if len(parts) % 2 == 1 and parts[-1].strip():\n",
    "        sentences.append(parts[-1].replace('\\x00', '.').strip())\n",
    "    return sentences\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[\\u201C\\u201D\\u201E]', '\"', text)  # \" \" „ -> \"\n",
    "    text = re.sub(r'[\\u2018\\u2019\\u201A]', \"'\", text)  # ' ' ‚ -> '\n",
    "    text = re.sub(r'[\\u00AB\\u00BB]', '\"', text)        # « » -> \"\n",
    "    text = re.sub(r\"[^a-zA-Z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u00FF0-9.,;:!?()'\\\"-]\", ' ', text)\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6b5c78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad6e2ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd45dedc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf7a382",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
